{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeef73f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import json\n",
    "import os\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "OUTPUT_DIR = \"../output/a100\"\n",
    "LLM_OUTPUT_DIR = \"../output/llm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08cefcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1933fa6b29460e8b8466e169dd5d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/613 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiments = list()\n",
    "\n",
    "for experiment_name in tqdm(os.listdir(OUTPUT_DIR)):\n",
    "    if experiment_name == \"output\":\n",
    "        continue\n",
    "\n",
    "    experiment_path = os.path.join(OUTPUT_DIR, experiment_name)\n",
    "\n",
    "    raw_params = experiment_name.split(\"_\")\n",
    "\n",
    "    if \"extra\" in raw_params[1]:\n",
    "        raw_params[0] = \"processed_extra\"\n",
    "        raw_params.remove(\"extra\")\n",
    "    elif \"processed\" in experiment_path and \"COVID19\" in experiment_path and \"v5\" in experiment_path:\n",
    "        continue\n",
    "\n",
    "    params = {\n",
    "        \"data\": raw_params[0],\n",
    "        \"dataset\": raw_params[1].replace(\"-\", \".\"),\n",
    "        \"learning_rate\": raw_params[2],\n",
    "        \"train_batch_size\": eval(raw_params[3]),\n",
    "        \"dropout\": eval(raw_params[4].replace(\"-\", \".\")),\n",
    "        \"version\": raw_params[5]   \n",
    "    }\n",
    "\n",
    "    if len(raw_params) > 6:\n",
    "        params[\"search_max_size\"] = eval(raw_params[6])\n",
    "        params[\"filter_domain\"] = eval(raw_params[7])\n",
    "        params[\"filter_social_media\"] = eval(raw_params[8])\n",
    "\n",
    "    for idx, char in enumerate(params[\"learning_rate\"]):\n",
    "        if char == \"-\" and params[\"learning_rate\"][idx-1] != \"e\":\n",
    "            params[\"learning_rate\"] = \\\n",
    "                params[\"learning_rate\"][:idx] + \".\" + params[\"learning_rate\"][idx+1:]\n",
    "\n",
    "    params[\"learning_rate\"] = eval(params[\"learning_rate\"])\n",
    "    params[\"experiment_name\"] = experiment_name\n",
    "\n",
    "    params = pd.Series(params)\n",
    "\n",
    "    with open(os.path.join(experiment_path, \"eval_results.txt\")) as f:\n",
    "        eval_metrics = f.read()\n",
    "        eval_metrics = eval_metrics.strip().split(\"\\n\")\n",
    "\n",
    "    eval_metrics = [metric.split(\" = \") for metric in eval_metrics]\n",
    "    eval_metrics = {metric[0]: eval(metric[1]) for metric in eval_metrics}\n",
    "    eval_metrics = pd.Series(eval_metrics)\n",
    "    eval_metrics.rename(\n",
    "        {\n",
    "            \"mcc\": \"test_mcc\",\n",
    "            \"accuracy\": \"test_acc\",\n",
    "            \"f1_score\": \"test_f1\",\n",
    "            \"tp\": \"test_tp\",\n",
    "            \"tn\": \"test_tn\",\n",
    "            \"fp\": \"test_fp\",\n",
    "            \"fn\": \"test_fn\",\n",
    "            \"auroc\": \"test_auroc\",\n",
    "            \"auprc\": \"test_auprc\",\n",
    "            \"eval_loss\": \"test_loss\"\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "\n",
    "    train_metrics = pd.read_csv(os.path.join(experiment_path, \"training_progress_scores.csv\"))\n",
    "    train_metrics.rename(columns={\n",
    "            \"mcc\": \"dev_mcc\",\n",
    "            \"accuracy\": \"dev_acc\",\n",
    "            \"f1_score\": \"dev_f1\",\n",
    "            \"tp\": \"dev_tp\",\n",
    "            \"tn\": \"dev_tn\",\n",
    "            \"fp\": \"dev_fp\",\n",
    "            \"fn\": \"dev_fn\",\n",
    "            \"auroc\": \"dev_auroc\",\n",
    "            \"auprc\": \"dev_auprc\",\n",
    "            \"global_step\": \"train_step\",\n",
    "            \"eval_loss\": \"dev_loss\"\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    train_metrics = train_metrics[train_metrics[\"dev_f1\"] == train_metrics[\"dev_f1\"].max()]\n",
    "    train_metrics = train_metrics.iloc[-1]\n",
    "    train_metrics[[\"dev_tp\", \"dev_tn\", \"dev_fp\", \"dev_fn\"]] \\\n",
    "         = train_metrics[[\"dev_tp\", \"dev_tn\", \"dev_fp\", \"dev_fn\"]].astype(int)\n",
    "    \n",
    "\n",
    "    experiment = pd.concat(\n",
    "        [params, train_metrics, eval_metrics]\n",
    "    )\n",
    "\n",
    "    experiments.append(experiment)\n",
    "\n",
    "experiments = pd.DataFrame(experiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec3e6a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>data</th>\n",
       "      <th>filter_social_media</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">COVID19.BR</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">processed_extra</th>\n",
       "      <th>False</th>\n",
       "      <td>82.1</td>\n",
       "      <td>82.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>77.9</td>\n",
       "      <td>78.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Fake.br</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">processed_extra</th>\n",
       "      <th>False</th>\n",
       "      <td>99.2</td>\n",
       "      <td>99.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>98.7</td>\n",
       "      <td>98.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                test_f1  test_acc\n",
       "dataset    data            filter_social_media                   \n",
       "COVID19.BR processed_extra False                   82.1      82.4\n",
       "                           True                    77.9      78.3\n",
       "Fake.br    processed_extra False                   99.2      99.2\n",
       "                           True                    98.7      98.8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra = experiments[experiments[\"data\"] == \"processed_extra\"]\n",
    "\n",
    "extra = extra[(extra[\"search_max_size\"] == 1) & (~extra[\"filter_domain\"])].drop(columns=\"search_max_size\")\n",
    "\n",
    "dev_max_extra = extra.groupby(\n",
    "    [\"dataset\", \"data\", \"filter_social_media\"]\n",
    ")\n",
    "dev_max_extra = dev_max_extra[\"dev_f1\"].max()\n",
    "\n",
    "best_dev_extra = extra[\n",
    "    extra.apply(lambda row: row[\"dev_f1\"] == dev_max_extra.loc[\n",
    "        (row[\"dataset\"], row[\"data\"],  row[\"filter_social_media\"])\n",
    "    ], axis=True)\n",
    "]\n",
    "best_dev_extra = best_dev_extra.drop_duplicates(\n",
    "    subset=[\"dataset\", \"data\", \"filter_social_media\"]\n",
    ")\n",
    "\n",
    "train_max_extra = best_dev_extra.groupby(\n",
    "    [\"dataset\", \"data\", \"filter_social_media\"]\n",
    ")\n",
    "train_max_extra = train_max_extra[[\"test_f1\", \"test_acc\"]].max()\n",
    "train_max_extra = (train_max_extra*100).round(1)\n",
    "train_max_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed774195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">COVID19.BR</th>\n",
       "      <th>processed</th>\n",
       "      <td>81.1</td>\n",
       "      <td>81.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw</th>\n",
       "      <td>81.9</td>\n",
       "      <td>82.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Fake.br</th>\n",
       "      <th>processed</th>\n",
       "      <td>98.9</td>\n",
       "      <td>98.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw</th>\n",
       "      <td>99.6</td>\n",
       "      <td>99.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      test_f1  test_acc\n",
       "dataset    data                        \n",
       "COVID19.BR processed     81.1      81.4\n",
       "           raw           81.9      82.1\n",
       "Fake.br    processed     98.9      98.9\n",
       "           raw           99.6      99.6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_extra = experiments[experiments[\"data\"] != \"processed_extra\"]\n",
    "\n",
    "dev_max_group = no_extra.groupby([\"dataset\", \"data\"])[\"dev_f1\"].max()\n",
    "\n",
    "best_dev = no_extra[\n",
    "    no_extra.apply(lambda row: row[\"dev_f1\"] == dev_max_group.loc[(row[\"dataset\"], row[\"data\"])], axis=True)\n",
    "]\n",
    "best_dev = best_dev.drop_duplicates(subset=[\"data\", \"dataset\"])\n",
    "\n",
    "train_max_group = best_dev.groupby([\"dataset\", \"data\"])[[\"test_f1\", \"test_acc\"]].max()\n",
    "train_max_group = (train_max_group*100).round(1)\n",
    "train_max_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f735bd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conjunto de dados</th>\n",
       "      <th>Processamento</th>\n",
       "      <th>F1 macro</th>\n",
       "      <th>Acurácia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID19.BR</td>\n",
       "      <td>3.a) Validado e Enquecido completo</td>\n",
       "      <td>82.1</td>\n",
       "      <td>82.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID19.BR</td>\n",
       "      <td>3.b) Validado e Enquecido filtrado</td>\n",
       "      <td>77.9</td>\n",
       "      <td>78.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fake.br</td>\n",
       "      <td>3.a) Validado e Enquecido completo</td>\n",
       "      <td>99.2</td>\n",
       "      <td>99.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fake.br</td>\n",
       "      <td>3.b) Validado e Enquecido filtrado</td>\n",
       "      <td>98.7</td>\n",
       "      <td>98.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID19.BR</td>\n",
       "      <td>2. Validado</td>\n",
       "      <td>81.1</td>\n",
       "      <td>81.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID19.BR</td>\n",
       "      <td>1. Original</td>\n",
       "      <td>81.9</td>\n",
       "      <td>82.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fake.br</td>\n",
       "      <td>2. Validado</td>\n",
       "      <td>98.9</td>\n",
       "      <td>98.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fake.br</td>\n",
       "      <td>1. Original</td>\n",
       "      <td>99.6</td>\n",
       "      <td>99.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Conjunto de dados                       Processamento  F1 macro  Acurácia\n",
       "0        COVID19.BR  3.a) Validado e Enquecido completo      82.1      82.4\n",
       "1        COVID19.BR  3.b) Validado e Enquecido filtrado      77.9      78.3\n",
       "2           Fake.br  3.a) Validado e Enquecido completo      99.2      99.2\n",
       "3           Fake.br  3.b) Validado e Enquecido filtrado      98.7      98.8\n",
       "0        COVID19.BR                         2. Validado      81.1      81.4\n",
       "1        COVID19.BR                         1. Original      81.9      82.1\n",
       "2           Fake.br                         2. Validado      98.9      98.9\n",
       "3           Fake.br                         1. Original      99.6      99.6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.concat([train_max_extra.reset_index(), train_max_group.reset_index()])\n",
    "result = results.fillna(False)\n",
    "\n",
    "results[\"data\"] = results.apply(\n",
    "    lambda row: \"filter_social_media\" if row[\"filter_social_media\"] == True else row[\"data\"], axis=True\n",
    ")\n",
    "results[\"data\"] = results[\"data\"].map(\n",
    "    {\n",
    "        \"raw\": \"1. Original\",\n",
    "        \"processed\": \"2. Validated\",\n",
    "        \"processed_extra\": \"3.a) Validated e full enrichment\",\n",
    "        \"filter_social_media\": \"3.b) Validated e filtered enrichment\"\n",
    "    }\n",
    ")\n",
    "\n",
    "results.drop(columns=\"filter_social_media\", inplace=True)\n",
    "\n",
    "results.rename(columns={\n",
    "    \"data\": \"processing\",\n",
    "}, inplace=True)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63d20b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [best_dev, best_dev_extra]\n",
    "experiments = pd.concat(experiments)\n",
    "df_analysis = {\n",
    "    d: pd.read_parquet(f\"../data/parquet/split/{d}.parquet\") for d in [\"Fake.br\", \"COVID19.BR\"]\n",
    "}\n",
    "\n",
    "\n",
    "df_analysis = {d: \n",
    "    df_analysis[d][df_analysis[d][\"new_split\"] == \"test\"][[\"text_no_url\", \"label\", \"google_search_results\"]] \n",
    "    for d in df_analysis}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b158223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, experiment in experiments.iterrows():\n",
    "    if experiment[\"dataset\"] == \"COVID19.BR\":\n",
    "        continue\n",
    "\n",
    "    analysis = pd.read_table(\n",
    "        os.path.join(\"..\", \"output\", \"a100\", experiment[\"experiment_name\"], \"test.tsv\"), index_col=0\n",
    "    )\n",
    "    analysis.index = [str(idx) for idx in analysis.index]\n",
    "    name = experiment[\"data\"]\n",
    "\n",
    "    if experiment[\"filter_social_media\"] == True:\n",
    "        name += \"_filter_social_media\"\n",
    "\n",
    "    df_analysis[experiment[\"dataset\"]][name] = analysis[\"pred_correct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc8abe5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d4f66515674b8eb40615108cee380d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_experiments = list()\n",
    "analysis_llm = dict()\n",
    "\n",
    "for experiment_name in tqdm(os.listdir(LLM_OUTPUT_DIR)):\n",
    "    experiment_path = os.path.join(LLM_OUTPUT_DIR, experiment_name)\n",
    "\n",
    "    if not os.path.exists(os.path.join(experiment_path, \"result.json\")):\n",
    "        continue\n",
    "\n",
    "    raw_params = experiment_name.split(\"_\")\n",
    "\n",
    "    if \"gemini-gemini\" in raw_params[0]:\n",
    "        raw_params[0] = raw_params[0].replace(\"gemini-gemini\", \"gemini/gemini\")\n",
    "    elif raw_params[:2] == ['vertex', 'ai-gemini-2-0-flash-001']:\n",
    "        raw_params[0] = 'vertex_ai/gemini-2-0-flash-001'\n",
    "        raw_params.remove('ai-gemini-2-0-flash-001')\n",
    "\n",
    "    if \"extra\" in raw_params[2]:\n",
    "        raw_params[1] = \"processed_extra\"\n",
    "        raw_params.remove(\"extra\")\n",
    "\n",
    "    link = raw_params[4] == \"link\"\n",
    "\n",
    "    if link:\n",
    "        raw_params.remove(\"link\")\n",
    "\n",
    "    if len(raw_params) > 5:\n",
    "        raw_params[5] = \"_\".join(raw_params[5:])\n",
    "        raw_params = raw_params[:6]\n",
    "\n",
    "    params = {\n",
    "        \"llm\": raw_params[0],\n",
    "        \"data\": raw_params[1],\n",
    "        \"dataset\": raw_params[2].replace(\"-\", \".\"),\n",
    "        \"few_shot\": raw_params[3],\n",
    "        \"version\": raw_params[4],\n",
    "        \"search_link\": link,\n",
    "        \"search_filter\": raw_params[5] if len(raw_params) > 5 else None   \n",
    "    }\n",
    "\n",
    "    if params[\"version\"] != \"v4\" and params[\"data\"] == \"processed_extra\":\n",
    "        continue\n",
    "\n",
    "    if params[\"llm\"] != \"gemini/gemini-1-5-flash\":\n",
    "        continue\n",
    "\n",
    "    if params[\"search_filter\"] in [\"filter_social_media_2\", \"filter_domains\"]:\n",
    "        continue\n",
    "\n",
    "    with open(os.path.join(experiment_path, \"result.json\")) as f:\n",
    "        report = json.load(f)\n",
    "\n",
    "    preds = pd.read_json(os.path.join(experiment_path, \"requests_results.jsonl\"), lines=True)\n",
    "\n",
    "    params[\"test_acc\"] = report[\"accuracy\"]\n",
    "    params[\"test_f1\"] = report[\"classification_report\"][\"macro avg\"][\"f1-score\"]\n",
    "    params[\"test_tp\"] = report[\"confusion_matrix\"][0][0]\n",
    "    params[\"test_tn\"] = report[\"confusion_matrix\"][1][1]\n",
    "    params[\"test_fp\"] = report[\"confusion_matrix\"][0][1]\n",
    "    params[\"test_fn\"] = report[\"confusion_matrix\"][1][0]\n",
    "\n",
    "    llm_experiments.append(params)\n",
    "\n",
    "    if params[\"dataset\"] not in analysis_llm:\n",
    "        analysis_llm[params[\"dataset\"]] = preds\n",
    "\n",
    "        analysis_llm[params[\"dataset\"]][\"text_a\"] = analysis_llm[params[\"dataset\"]][\"dataset_row\"].apply(lambda d: d.get(\"text_a\", d.get(\"text\")))\n",
    "\n",
    "\n",
    "        if \"text_b\" in analysis_llm[params[\"dataset\"]][\"dataset_row\"][0].keys():\n",
    "            analysis_llm[params[\"dataset\"]][\"text_b\"] = analysis_llm[params[\"dataset\"]][\"dataset_row\"].apply(lambda d: d[\"text_b\"])\n",
    "\n",
    "        analysis_llm[params[\"dataset\"]][\"labels\"] = analysis_llm[params[\"dataset\"]][\"dataset_row\"].apply(lambda d: d[\"labels\"])\n",
    "\n",
    "        name = params[\"data\"]\n",
    "        \n",
    "        if params[\"search_filter\"]:\n",
    "            name += f\"_{params['search_filter']}\"\n",
    "\n",
    "        analysis_llm[params[\"dataset\"]].rename(\n",
    "            columns={\"is_correct\": name}, inplace=True)\n",
    "\n",
    "        #analysis_llm[params[\"dataset\"]] = analysis_llm[params[\"dataset\"]].set_index(\"dataset_index\")\n",
    "\n",
    "        analysis_llm[params[\"dataset\"]].drop(\n",
    "            columns=[\n",
    "                \"response_text\",\"order\", \"dataset_row_tag_label\", \n",
    "                \"response_tag_label\", \"config\", \"response_raw\", \"response_label\", \n",
    "                \"model\", \"dataset_row\"\n",
    "            ],\n",
    "            inplace=True\n",
    "        )\n",
    "    else:\n",
    "        if \"text_b\" not in analysis_llm[params[\"dataset\"]].columns and \"text_b\" in preds[\"dataset_row\"][0]:\n",
    "            analysis_llm[params[\"dataset\"]][\"text_b\"] = preds[\"dataset_row\"].apply(lambda d: d[\"text_b\"])\n",
    "        \n",
    "        name = params[\"data\"]\n",
    "        if params[\"search_filter\"]:\n",
    "            name += f\"_{params['search_filter']}\"\n",
    "\n",
    "        analysis_llm[params[\"dataset\"]][name] = preds[\"is_correct\"]\n",
    "\n",
    "llm_experiments = pd.DataFrame(llm_experiments)\n",
    "llm_experiments[\"filter_social_media\"] = llm_experiments[\"search_filter\"].map(lambda s: pd.notna(s))\n",
    "llm_experiments.drop(columns=[\"search_link\", \"version\", \"few_shot\", \"llm\", \"search_filter\"], inplace=True)\n",
    "llm_experiments[\"data\"] = llm_experiments.apply(\n",
    "    lambda row: \"filter_social_media\" if row[\"filter_social_media\"] == True else row[\"data\"], axis=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0861537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_experiments[\"data\"] = llm_experiments[\"data\"].map(\n",
    "    {\n",
    "        \"raw\": \"1. Original\",\n",
    "        \"processed\": \"2. Validate\",\n",
    "        \"processed_extra\": \"3.a) Validado e full enrichment\",\n",
    "        \"filter_social_media\": \"3.b) Validado e filtered enrichment\"\n",
    "    }\n",
    ")\n",
    "\n",
    "llm_experiments.drop(columns=\"filter_social_media\", inplace=True)\n",
    "\n",
    "llm_experiments.rename(columns={\n",
    "    \"data\": \"processing\",\n",
    "}, inplace=True)\n",
    "\n",
    "llm_experiments = llm_experiments.set_index(\n",
    "    [\"dataset\", \"processing\"]\n",
    ")\n",
    "llm_experiments = llm_experiments.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c64cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_experiments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake_news",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
